# -*- coding: utf-8 -*-
"""BankChurners LogisticRegression.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1y9DA9zurWzaD0OreNp5QzZcMN4e-q1-c
"""

import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

dataset_check = pd.read_csv('BankChurners.csv')

dataset_check.head()

dataset_check.info()

dataset_check.isnull().sum()

dataset_check.describe()

dataset_check=dataset_check.drop(dataset_check.iloc[:,21:],axis=1)

dataset_check.head()

dataset_check['Attrition_Flag'].unique()

dataset_check.shape

dataset_check.columns

df_all=dataset_check.drop_duplicates()

df_all.drop_duplicates().shape
#it means the dataset had no duplicates

#if dataset had duplicates we could remove it like this
#df_all = df_all.drop_duplicates(subset=None , keep='first')
#but we had no duplicates so no need to try this method at any column

import matplotlib.pyplot as plt
plt.figure(figsize=(5,3))



ax=sns.histplot(data=df_all,
               x='Customer_Age',
               bins=range(df_all['Customer_Age'].min(),df_all['Customer_Age'].max())
               )

for p in ax.patches:
    height=p.get_height()
    ax.annotate(
        f'{height}',
        (p.get_x()+p.get_width()/2,height),
        ha='center',va='bottom',
        xytext=(0,2),
        textcoords='offset points',
        fontsize=7,
        rotation=90,

    )

df_all['Credit_Limit'].dtype

#create automatic one function for histograms for labelling median dotted line with linestyle=":" also in the histogram
def histoplotting(column_name,hue_=None):

    if df_all[column_name].dtype == 'float64':
        df_all[column_name]=df_all[column_name].astype('int64')

    plt.figure(figsize=(6,3))

    maximum = df_all[column_name].max()
    minimum = df_all[column_name].min()

    median = df_all[column_name].median()

    if hue_:
        ax=sns.histplot(x=df_all[column_name],
                        bins=range(minimum,maximum+1),
                        hue=hue_,
                        multiple='dodge'
                       )
    else:
         ax=sns.histplot(x=df_all[column_name],
                        bins=range(minimum,maximum+1)
                        )


    #labelling the bars in the histogram
    #running a for loop for each bar

    for p in ax.patches:
        height = p.get_height()
        ax.annotate(
            f'{height}',
            (p.get_x()+p.get_width()/2,p.get_height()),
            xytext=(0,4),
            textcoords='offset points',
            va='bottom',ha='center',
            rotation=90,
            fontsize=7
        )
    #outside the for loop as median is singular
    #represent the axv line using dotted red color line for the representation of median in the particular column

    plt.axvline(x=median, linestyle=":",color='red',linewidth=2)
    #for labelling median axvline using plotlib
    plt.text(median, plt.ylim()[0]-0*plt.ylim()[1],f'Median={median}',color='red',ha='center',va='top')
    #plt.ylim() return tuple(ymin,ymax) in order to  get just upper limit of y axis we use plt.ylim()[1]


    plt.show()

histoplotting('Customer_Age')

df_all.head()

df_all['Avg_Utilization_Ratio'] = df_all['Avg_Utilization_Ratio'].round(1)
df_all.head()

bins= pd.cut(df_all['Customer_Age'],bins=4)
labels_tuples = bins.cat.categories
labels_list = list(f'{int(left)}-{int(right)}'for left,right in zip(labels_tuples.left,labels_tuples.right))


#intorduced a new column in the dataframe df_all
df_all['Customer_Age_Seg'] = pd.cut(df_all['Customer_Age'],bins=4,labels=labels_list)
df_all['Customer_Age_Seg'].head()

df_all.head()

df_income_age = df_all.groupby(['Income_Category','Customer_Age_Seg'])['Customer_Age_Seg'].value_counts().reset_index()

barplotting(df_income_age,'Income_Category','count','Customer_Age_Seg')

plt.figure(figsize=(7,5))


colors = ['blue','green','red','yellow']
sns.histplot(data=df_income_age,
           x='Income_Category',
           hue='Customer_Age_Seg',
           weights='count',
               shrink=0.8,
           palette=colors,
           multiple='stack')

plt.show()

barplotting(df_all,'Marital_Status','Avg_Utilization_Ratio')

#Segment customers by income level and analyze spending patterns or churn rates.
df_churn_income = df_all.groupby('Income_Category')['Attrition_Flag'].value_counts().reset_index()
df_churn_income

barplotting(df_churn_income,'Income_Category','count','Attrition_Flag')

#Exploring the transaction frequency of each customer and based on dependent_count as a hue
order = [0,1,2,3,4,5]
df_all['Dependent_count'] = pd.Categorical(df_all['Dependent_count'],categories=order,ordered=True)

plt.figure(figsize = (10,5))


minimum = df_all['Total_Trans_Ct'].min()
maximum = df_all['Total_Trans_Ct'].max()

median = df_all['Total_Trans_Ct'].median()
ax=sns.histplot(data = df_all,
            x='Total_Trans_Ct',
            bins=range(minimum,maximum+1,10),
            hue='Dependent_count',
            multiple='dodge'
               )

#outside the for loop as median is singular
#represent the axv line using dotted red color line for the representation of median in the particular column

plt.axvline(x=median, linestyle=":",color='red',linewidth=2)
#for labelling median axvline using plotlib
plt.text(median,plt.ylim()[1]*0.9,f'Median={median}',color='red',ha='center',va='center')
#plt.ylim() return tuple(ymin,ymax) in order to  get just upper limit of y axis we use plt.ylim()[1]
plt.xlabel(range(minimum,maximum+1,10))


plt.show()

#creating seperate column for transaction count categories and then creating a dataframe for dependents vs trans ct.
#creating a stack histplot for this purpose

bins_edges = pd.cut(df_all['Total_Trans_Ct'],bins=4).cat.categories
#picking out list of categories
labels = list(f'{int(left)}-{int(right)}'for left,right in zip(bins_edges.left,bins_edges.right))

df_all['Trans_Ct_Seg'] = pd.cut(df_all['Total_Trans_Ct'],bins=4,labels=labels)

#creating a datframe to calculate the total recordings in the dataset for the transaction counts categories
#taking depemdent count as a hue

df_trans_dep = df_all.groupby(['Trans_Ct_Seg','Dependent_count'])['Dependent_count'].value_counts().reset_index()
df_trans_dep.head()

#create a histplot with count as a weights and dependent count as a hue
plt.figure(figsize=(5,5))

sns.histplot(data=df_trans_dep,
            x='Trans_Ct_Seg',
            hue='Dependent_count',
            weights='count',
            shrink=0.7,
            multiple='stack')

plt.title('Transactions VS Dependents of a Family')
plt.show()

order=[ 'Unknown','Less than $40K','$120K +', '$40K - $60K', '$60K - $80K', '$80K - $120K']

df_all['Income_Category'] = pd.Categorical(df_all['Income_Category'], categories=order)

"""Average Credit Limit: Analyze the average credit limit by customer segment (e.g., by income, age group, or gender)."""

#Grouping the avg credit limits according to income categories but remember to analyze AVG
#Analyzing according to hue married/single
df_income_vs_credit = df_all[['Income_Category','Credit_Limit','Marital_Status']].groupby(['Income_Category','Marital_Status'])['Credit_Limit'].mean().reset_index()
df_income_vs_credit['Credit_Limit'] = df_income_vs_credit['Credit_Limit'].round(1)

df_income_vs_credit

#Now showing this above dataframe through bar plot giving marital status as a hue
barplotting(df_income_vs_credit,'Income_Category','Credit_Limit','Marital_Status')

#and creating without hue
barplotting(df_income_vs_credit,'Income_Category','Credit_Limit')

#Observe the male/female category in each eduaction level criterion
#for this purpose creating a seperate dataframe so that no complexity is to be faced

df_edu_gender = df_all.groupby('Education_Level')['Gender'].value_counts().reset_index()

barplotting(df_edu_gender,'Education_Level','count','Gender')

#lets find out males or females have spent more months on book
#obviously the population of females is more but what if unexpectedtly males might have spent more months on book

#we will be just calculating the average months on book for males and females
df_avg_months = df_all[['Gender','Months_on_book']].groupby('Gender').agg({'Months_on_book':'mean'}).reset_index()
#df_avg_months

#displaying it in the form of pie chart
plt.figure(figsize=(3,3))
labels=df_avg_months['Gender'].unique()
plt.pie(df_avg_months['Months_on_book'],labels=labels,autopct='%1.1f%%',startangle=145,colors=['pink','skyblue'])
plt.plot()

"""Despite the fact that there were more females approx 5% more than males but still both spent almost equal months on bank."""

df_all['Gender'] = pd.Categorical(df_all['Gender'])

df_gen_count = df_all['Gender'].value_counts().reset_index()
plt.figure(figsize=(3,3))
labels=df_gen_count['Gender'].unique()


plt.pie(df_gen_count['count'],labels=labels,autopct="%1.1f%%",startangle=45,colors=['pink','skyblue'])
plt.plot()

#seeing the categories of education level how many people belong to which category and having Card_Category as a hue
df_all['Education_Level'] = pd.Categorical(df_all['Education_Level'])
df_edu = df_all[['Education_Level','Card_Category']].groupby(['Education_Level','Card_Category']).value_counts().reset_index()
df_edu

#creating a histogram for having card as a hue

plt.figure(figsize=(10,3))

sns.barplot(data=df_edu,
            x='Education_Level',
            y='count',
            hue='Card_Category')

#creating a dataframe for comparing card holders and their attrition flag status regarding their gender
df_att_card = df_all[['Card_Category','Attrition_Flag','Gender']].groupby(['Card_Category','Attrition_Flag','Gender']).value_counts().reset_index()
df_att_card

#creating histogram for comparing card holders and attrition flag but having gender as a hue

plt.figure(figsize=(7,5))

sns.barplot(data=df_att_card,
           x='Card_Category',
           y='count',
           hue='Attrition_Flag',
           palette='pastel')
plt.plot()

#creating a dataframe for male/female holding which card categories
#creating a pie chart for showing the percentages of male female different card category holders

df_all['Card_Category'].unique()

#converting card categories into categorical columns
order = ['Blue','Platinum','Silver','Gold']
df_all['Card_Category'] = pd.Categorical(df_all['Card_Category'],
                                         categories=order,
                                         ordered=True)

df_card =  df_all[['Gender','Card_Category']].groupby(['Gender','Card_Category']).value_counts().reset_index()
df_card

barplotting(df_card,'Card_Category','count','Gender')

#introducing a new quartile column
df_all['Revolving_Bal_Quartile'],q_edges= pd.qcut(df_all['Total_Revolving_Bal'],
                q=4,
                labels=['Q1','Q2','Q3','Q4'],
                retbins=True)
df_all.head()

df_income = df_all[['Education_Level','Income_Category']].groupby(['Education_Level','Income_Category']).value_counts().reset_index()

df_income

barplotting(df_income,'Education_Level','count','Income_Category')

#grouping according to balance quarter ranges and according to hue of education/salary/Attrition Flag Status
df_bal = df_all[['Revolving_Bal_Quartile','Attrition_Flag']].groupby(['Revolving_Bal_Quartile','Attrition_Flag']).value_counts().reset_index()
df_bal

print(q_edges)
#q_edges has my revolving balance categories stored which i will be plotting on axis as plt.x_label

barplotting(df_bal,'Revolving_Bal_Quartile','count','Attrition_Flag')
#plt.xlabel(q_edges)

histoplotting('Months_on_book')

df_all['Months_Inactive_12_mon'].unique()

#creating a mini dataset of counting how many customers were inactive for how many months in the past 12 months inactivation

mini_df = df_all[['Months_Inactive_12_mon','Gender']].value_counts()
mini_df = mini_df.reset_index(name='count')
mini_df = mini_df.sort_values(by='Months_Inactive_12_mon',ascending=True)

mini_df

def barplotting(df,col1,col2,hue_=None):
    plt.figure(figsize=(10,4))

    if hue_:
        ax=sns.barplot(data=df,
                      x=col1,
                      y=col2,
                      hue=hue_,
                      palette='viridis')
    if not hue_:
        ax=sns.barplot(data=df,
                      x=col1,
                      y=col2,
                      #hue=hue_,
                      palette='viridis')

    #labelling purposes
    for p in ax.patches:
        height = p.get_height()
        ax.annotate(
            f'{height:.0f}',
            (p.get_x()+p.get_width()/2,p.get_height()),
            xytext=(0,4),
            textcoords='offset points',
            va='bottom',ha='center',
            rotation=90,
            fontsize=7
        )

    plt.show()

barplotting(mini_df,'Months_Inactive_12_mon','count','Gender')

plt.figure(figsize=(6,3))

ax = sns.barplot(
           x='Months_Inactive_12_mon',
           y= 'count',
           hue='Gender',
          data = mini_df,
    palette = 'viridis'
)


for p in ax.patches:
    height = p.get_height()
    ax.annotate(
        f'{height}',
        (p.get_x()+p.get_width()/2,p.get_height()),
        xytext=(0,4),
        textcoords='offset points',
        va='bottom',ha='center',
        rotation=90,
        fontsize=7
    )

plt.plot()

histoplotting('Months_Inactive_12_mon')

df_all.shape

# # Map 'Attrited Customer' to 1 and 'Existing Customer' to 0
# df_all['Attrition_Flag'] = df_all['Attrition_Flag'].map({
#     'Attrited Customer': 0,
#     'Existing Customer': 1
# })

# # Verify the conversion
# df_all['Attrition_Flag'].unique()

columns_to_drop = df_all.iloc[:,21:]
df_all.drop(columns_to_drop,axis=1,inplace=True)

df_all.columns

# Columns to encode
col = ['Gender', 'Education_Level', 'Marital_Status', 'Income_Category', 'Card_Category']

df_all[col] = df_all[col].astype('category')

#apply cat.codes method to make binary + multiple encoding columns

df_all[col] = df_all[col].apply(lambda x: x.cat.codes)
df_all.head()

numerical = df_all.select_dtypes(include=['number'])
categorical = df_all['Attrition_Flag']
df_all_features = pd.concat([numerical,categorical], axis=1)
df_all_features.columns

df_all_features.shape

columns_drop  = df_all_features[['CLIENTNUM','Total_Amt_Chng_Q4_Q1','Total_Ct_Chng_Q4_Q1']]
features_df = df_all_features.drop(columns_drop, axis=1)
features_df.head()

features_df.shape

#visualizing outliers in the Customer Age
plt.figure(figsize=(5,3))
sns.boxplot(features_df, x= 'Customer_Age')

"""Deciding to keep the outliers as the customers with old age might be meaningful for predicting churn rate."""

plt.figure(figsize=(5,3))
sns.boxplot(features_df, x= 'Total_Trans_Ct')

#creating a pair plot to observe relations between different columns

#hue can be set to see the churn and non-churn in two different colours (Exisitng / Attrited Customer)
plt.figure(figsize=(5,5))
sns.pairplot(features_df, hue = 'Attrition_Flag')
plt.show()

#converting Attrited_Flag column into numerical
# Map 'Attrited Customer' to 1 and 'Existing Customer' to 0
features_df['Attrition_Flag'] = features_df['Attrition_Flag'].map({
    'Attrited Customer': 0,
    'Existing Customer': 1
})

# Verify the conversion
features_df['Attrition_Flag'].unique()

"""The two classes are pretty imbalanced non-churners are a minority class.
Even after applying class_weight='balanced' the LogisticRegression is not producing good results.
Hence applying:
#SMOTE TECHNIQUE:
OverSampling the minority class.

Furthermore this sampling technique is applied only on training data.

"""

df = features_df.groupby('Attrition_Flag').size()
print(df)

"""Finding out 10 best features out of 16 to include in our classical ML Models using:


1.RFE (RECUSRSIVE FEATURE ELIMINATION)

2.LassoCV
"""

from sklearn.preprocessing import StandardScaler
from sklearn.feature_selection import RFE
from sklearn.linear_model import LogisticRegression

X = features_df.drop('Attrition_Flag', axis=1)
y = features_df['Attrition_Flag']


scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)
rfe = RFE(estimator=LogisticRegression(), n_features_to_select=17, step=1) #remove 1 feature in each step
rfe.fit(X_scaled, y)

# Get the selected features
selected_features = X.columns[rfe.support_]
selected_features

"""for improved and better performance over the class 0 : non-churners.
Include the more amount of columns/features and then try running your model to see the evaluation results.

Like your task is to encode the 'marital status', 'card category', 'income category','education category' such columns.

Make new columns in the dataframe for each of the above mentioned columns as like 'marital status encoded' and include those new columns in the lasso CV for selecting features and then run you model and see the performance.
"""

# for improved and better performance over the class 0 : non-churners.
# Include the more amount of columns/features and then try running your model to see the evaluation results.

# Like your task is to encode the 'marital status', 'card category', 'income category','education category' such columns.

# Make new columns in the dataframe for each of the above mentioned columns as like 'marital status encoded'
# and include those new columns in the lasso CV for selecting features and then run you model and see the performance.

"""simply map the binary categorical columns .
no need to create new columns in the dataframe for such columns.

just like you mapped the' attrited flag ' column .

and encode other categorical columns having more than one categories.
"""

#using lassoCV for selecting features
from sklearn.linear_model import LassoCV
from sklearn.preprocessing import StandardScaler



scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

lasso = LassoCV(cv=17, random_state=42)
lasso.fit(X_scaled, y)

selected_features = X.columns[lasso.coef_ != 0]
selected_features

"""#LOGISTIC REGRESSION

Predicting Churn Rate
"""

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report
from sklearn.preprocessing import StandardScaler
from imblearn.over_sampling import SMOTE

#splitting data
X_selected = selected_features
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size = 0.2, random_state = 42)

#applying SMOTE
X_train_resampled, y_train_resampled = SMOTE().fit_resample(X_train, y_train)

#initializing the LogisticRegression Model

logreg = LogisticRegression(class_weight = 'balanced', random_state = 42)

#fitting the model on SMOTE resampled data

logreg.fit(X_train_resampled,y_train_resampled)

#predecting
y_pred = logreg.predict(X_test)
y_pred_proba = logreg.predict_proba(X_test)

"""#CLASSIFICATION REPORT"""

print(classification_report(y_test,y_pred))

from sklearn.metrics import confusion_matrix
conf = confusion_matrix(y_test,y_pred)

#plotting heatmap
sns.heatmap(conf,annot=True,fmt='d')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.show()

client_num =